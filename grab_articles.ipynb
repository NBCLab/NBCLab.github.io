{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download new lab publication information from PubMed\n",
    "We use this notebook to periodically search for, and download information about, new papers by either Dr. Laird or Dr. Sutherland. This notebook uses BioPython's PubMed search tool to grab information from PubMed based on search criteria. Then, we build a publication-specific MarkDown file for each new paper. A lot of the elements of the file are automatically set up. The only thing you generally have to check is that the journal cover that the MarkDown file automatically points to exists. If the image doesn't exist, search online for a good one, export to PNG, and reduce the size to ~150px by 300px.\n",
    "\n",
    "You might also want to check new papers for relevant info, like a link to a GitHub repository or OpenNeuro collection, that might be found in the text.\n",
    "\n",
    "Unfortunately, this notebook cannot find new preprints, so the associated website files must be created manually. We also have to merge those files with the version grabbed from PubMed once the preprint is published by hand.\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Run this notebook.\n",
    "2. If any new papers were grabbed, check the following:\n",
    "    1. The journal image exists.\n",
    "    2. The paper has either of the lab PIs as an author. Ensure that it isn't by *another* AR Laird or MT Sutherland.\n",
    "    3. The paper is not a duplicate of a preprint or another version of the paper. If so, merge the two versions.\n",
    "3. Save the changes to the notebook.\n",
    "4. Push changes to the notebook and affected files to GitHub.\n",
    "5. Open a pull request to NBCLab/NBCLab.github.io."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from glob import glob\n",
    "\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only grab papers from after the lab PIs came to FIU.\n",
    "searches = [\n",
    "    '\"Laird AR\"[AUTH] AND (\"2012/01/01\"[PDAT] : \"3000/12/31\"[PDAT])',\n",
    "    '\"Sutherland MT\"[AUTH] AND (\"2012/01/01\"[PDAT] : \"3000/12/31\"[PDAT])',\n",
    "]\n",
    "\n",
    "# Papers indexed on PubMed, but not captured by the searches.\n",
    "other_pmids = [\n",
    "    \"33749724\",\n",
    "    \"33932337\",\n",
    "]\n",
    "pmid_search = \"[PMID] OR \".join(other_pmids) + \"[PMID]\"\n",
    "searches.append(pmid_search)\n",
    "\n",
    "# Extract all publications matching term.\n",
    "Entrez.email = 'tsalo006@fiu.edu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for TERM in searches:\n",
    "    h = Entrez.esearch(db='pubmed', retmax='2', term=TERM)\n",
    "    result = Entrez.read(h)\n",
    "    print('Total number of publications containing {0}: {1}'.format(TERM, result['Count']))\n",
    "    h_all = Entrez.esearch(db='pubmed', term=TERM, retmax=result['Count'])\n",
    "    result_all = Entrez.read(h_all)\n",
    "    ids_all = result_all['IdList']\n",
    "    h = Entrez.efetch(db='pubmed', id=ids_all, rettype='medline', retmode='text')\n",
    "    records = Medline.parse(h)\n",
    "\n",
    "    acceptable_formats = ['journal article', 'comparative study', 'editorial',\n",
    "                          'introductory journal article']\n",
    "    for record in records:\n",
    "        if any([type_.lower() in acceptable_formats for type_ in record.get('PT')]):\n",
    "            pmid = record.get('PMID')\n",
    "            pmcid = record.get('PMC', '')\n",
    "\n",
    "            doi = [aid for aid in record.get('AID', []) if aid.endswith(' [doi]')]\n",
    "            if doi:\n",
    "                doi = doi[0].replace(' [doi]', '')\n",
    "            else:\n",
    "                doi = ''\n",
    "\n",
    "            title = record.get('TI').rstrip('.')\n",
    "            authors = record.get('AU')\n",
    "\n",
    "            pub_date = parser.parse(record.get('DP'))\n",
    "            year = pub_date.year\n",
    "            month = pub_date.month\n",
    "            day = pub_date.day\n",
    "\n",
    "            journal = record.get('TA')\n",
    "            volume = record.get('VI', '')\n",
    "            issue = record.get('IP', '')\n",
    "            pages = record.get('PG', '')\n",
    "\n",
    "            abstract = record.get('AB', '')\n",
    "\n",
    "            row = [pmid, pmcid, doi, title, authors, year, month,\n",
    "                   day, journal, volume, issue, pages, abstract]\n",
    "            rows += [row]\n",
    "\n",
    "# Save all relevant info from articles to a csv.\n",
    "df = pd.DataFrame(columns=['pmid', 'pmcid', 'doi', 'title', 'authors',\n",
    "                           'year', 'month', 'day',\n",
    "                           'journal', 'volume', 'issue', 'pages',\n",
    "                           'abstract'],\n",
    "                  data=rows)\n",
    "df = df.sort_values(by=['pmid'])\n",
    "df.to_csv('articles.tsv', sep=\"\\t\", line_terminator=\"\\n\", index=False)\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab our markdown file template\n",
    "with open('papers/_posts/template_with_stuff.md', 'r') as fo:\n",
    "    template = fo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_papers = sorted(glob('papers/_posts/20*.md'))\n",
    "\n",
    "# One paper is by another MT Sutherland.\n",
    "# Something to do with mouse teeth.\n",
    "skip_pmids = ['28650075']\n",
    "\n",
    "# Add papers we already have pages for.\n",
    "old_pmids = skip_pmids\n",
    "for pap in old_papers:\n",
    "    # Grab each existing article's PMID\n",
    "    with open(pap, 'r') as fo:\n",
    "        dat = fo.readlines()\n",
    "    line = [l for l in dat if l.startswith('pmid:')][0]\n",
    "    pmid = line.replace('pmid:', '').strip()\n",
    "    old_pmids.append(pmid)\n",
    "    old_pmids = [pmid for pmid in old_pmids if pmid]\n",
    "print(\"{} existing articles found.\".format(len(old_papers)))\n",
    "print(\"{} existing articles with PubMed IDs found.\".format(len(old_pmids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a small check. Unnecessary for the notebook.\n",
    "journals = df['journal'].str.lower().unique()\n",
    "print(journals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create files for new articles\n",
    "for _, row in df.iterrows():\n",
    "    pmid = row['pmid']\n",
    "    if str(pmid) not in old_pmids:\n",
    "        # This appears broken. 'authors' is now a list of strings.\n",
    "        # authors = ast.literal_eval(row['authors'])\n",
    "        authors = row['authors']\n",
    "        nick = [re.sub(r'\\W+', '', w) for w in row['title'].lower().split(' ')[:3]]\n",
    "        nickname = '{0}-{1}-{2}-{3}-{4}'.format(row['year'],\n",
    "                                                '{0:02d}'.format(int(row['month'])),\n",
    "                                                '{0:02d}'.format(int(row['day'])),\n",
    "                                                authors[0].split(' ')[0].lower(),\n",
    "                                                '-'.join(nick))\n",
    "        nickname = nickname.replace(':', '')\n",
    "        journal = row['journal']\n",
    "        image = '/assets/images/papers/{0}.png'.format('-'.join(journal.lower().split(' ')))\n",
    "        title = row['title'].replace('\"', \"'\")\n",
    "        completed = template.format(title=title, nickname=nickname,\n",
    "                                    authors=', '.join(authors), year=int(row['year']),\n",
    "                                    journal=journal, volume=row['volume'],\n",
    "                                    image=image,\n",
    "                                    issue=row['issue'], pages=row['pages'],\n",
    "                                    pmcid=row['pmcid'], doi=row['doi'], pmid=row['pmid'],\n",
    "                                    abstract=row['abstract'])\n",
    "        with open('papers/_posts/{0}.md'.format(nickname), 'w') as fo:\n",
    "            fo.write(completed)\n",
    "\n",
    "        print('New file created for {0}'.format(pmid))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
